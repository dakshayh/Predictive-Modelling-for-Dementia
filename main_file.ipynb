{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import seaborn as sb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_df = pd.read_csv('oasis_cross-sectional.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = pd.read_csv(\"oasis_longitudinal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = long_df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = cross_df[cross_df['ID'].isin([a])]\n",
    "b\n",
    "#Cross sectional data and longitudinal data are not related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longitudinal data set into consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "long_df = long_df.drop(\"Subject ID\",axis = 1)\n",
    "long_df = long_df.drop(\"MRI ID\",axis =1)\n",
    "#dropping Hand column\n",
    "long_df=long_df.drop(\"Hand\",axis=1)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing NaN values\n",
    "long_df.SES = long_df.SES.fillna(round(long_df.SES.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.MMSE = long_df.MMSE.fillna(round(long_df.MMSE.mean()))\n",
    "long_df['Group'] = long_df['Group'].replace('Converted','Demented') \n",
    "#creating dummy variables\n",
    "long_df = pd.get_dummies(data= long_df,columns = {'Group','M/F'})\n",
    "long_df = long_df.rename(columns={'M/F_F':'Female','M/F_M':'Male','Group_Demented':'Demented','Group_Nondemented':'Non-Demented'})\n",
    "#Male=1 and Female=0\n",
    "long_df=long_df.drop(\"Female\",axis=1)\n",
    "long_df = long_df.rename(columns={\"Male\":\"Gender\"})\n",
    "#Demented=1 and Non-demented=0\n",
    "long_df = long_df.drop(\"Non-Demented\",axis=1)\n",
    "long_df = long_df.rename(columns={\"Demented\":\"Group\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_graph(X):\n",
    "    demented = long_df[long_df['Group']==1][X].value_counts()\n",
    "    non_demented = long_df[long_df['Group']==0][X].value_counts()\n",
    "    bar_df = pd.DataFrame([demented,non_demented])\n",
    "    bar_df =bar_df.rename(columns={0:'Female',1:'Male'})\n",
    "    bar_df.index = ['Demented','Non-demented']\n",
    "    bar_df.plot(kind=\"bar\",stacked=\"true\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bar_graph('Gender')\n",
    "plt.title(\"Gender vs Dementia\")\n",
    "plt.ylim(0,200,10)\n",
    "plt.ylabel('Number of people')\n",
    "plt.legend(loc=\"center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 10,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_graph(X):\n",
    "    demented = long_df[long_df['Group']==1][X]\n",
    "    non_demented = long_df[long_df['Group']==0][X]\n",
    "    box_data = [demented,non_demented]\n",
    "    plt.boxplot(box_data,patch_artist=True,labels=['Demented','Non-demented'],widths = (0.5,0.5),vert=False,showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_graph('MMSE')\n",
    "plt.xlim(12,36,2)\n",
    "plt.xlabel('MMSE')\n",
    "plt.title('Impact of MMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def violin_graph(X):\n",
    "    w=long_df['Group'].replace([0,1],['Non-demented','Demented'])\n",
    "    y=long_df[X] \n",
    "    violin_df=pd.DataFrame([w,y]).T\n",
    "    sb.violinplot(x=y, y=w,data=violin_df,palette='rainbow',linewidth=3, orient='h')    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_graph('EDUC')\n",
    "plt.xlabel(\"Education(in years)\",fontsize=14)\n",
    "plt.ylabel(\"Group\",fontsize = 14)\n",
    "plt.xticks(np.arange(2,28,2))\n",
    "plt.title(\"Impact of Education\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(long_df) \n",
    "X = scaler.transform(long_df);X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = long_df['Group']\n",
    "x_pca = long_df[['Age', 'EDUC', 'SES', 'MMSE', 'eTIV',\n",
    "       'nWBV', 'ASF', 'Gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying PCA to training features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(x_pca) \n",
    "X = scaler.transform(x_pca);X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting of top two components of pca to explain linear separability of two components through the plotting\n",
    "from sklearn.decomposition import PCA\n",
    "covar_matrix = PCA(n_components = 2)\n",
    "yoyo= covar_matrix.fit_transform(X)\n",
    "variance = covar_matrix.explained_variance_ratio_ #calculate variance ratios\n",
    "sb.scatterplot(x=yoyo[:,0],y=yoyo[:,1],hue=y)\n",
    "var=np.cumsum(np.round(covar_matrix.explained_variance_ratio_, decimals=3)*100)\n",
    "var #cumulative sum of variance explained with [n] features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel('% Variance Explained')\n",
    "plt.xlabel('# of Features')\n",
    "plt.title('PCA Analysis')\n",
    "plt.ylim(30,100.5)\n",
    "plt.style.context('seaborn-whitegrid')\n",
    "plt.plot(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Age', 'EDUC', 'SES', 'MMSE', 'eTIV',\n",
    "       'nWBV', 'ASF', 'Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    y = long_df['Group']\n",
    "    x = long_df[['Age', 'EDUC', 'SES', 'MMSE', 'eTIV',\n",
    "       'nWBV', 'ASF', 'Gender']]\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.30,random_state = 0)\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, auc,precision_score\n",
    "compare=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    LogModel = LogisticRegression(solver='lbfgs').fit(X_train,Y_train)#vanilla logistic regression\n",
    "    Y_predicted = LogModel.predict(X_test)\n",
    "    acc = accuracy_score(Y_test,Y_predicted)\n",
    "    recall = recall_score(Y_test,Y_predicted,pos_label=1)\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test,Y_predicted,pos_label=1)\n",
    "    AUC = auc(fpr,tpr)\n",
    "    compare.append(['Logistic Regression',acc,recall,AUC,fpr,tpr,thresholds])\n",
    "    compare\n",
    "#Explain the coefficients and results\n",
    "#explain vs predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDR(Clinical dementia rating)\n",
    "\n",
    "CDR is solely responsible to say about the rating of dementia. Hence do not take the feature into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogModel.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the regression coefficients(how much impact the outputs have on the features)\n",
    "LogModel.coef_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array([columns]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance=pd.DataFrame(np.hstack((np.array([columns]).T, LogModel.coef_.T)), \n",
    "                                columns=['feature', 'importance'])\n",
    "feature_importance['importance']=pd.to_numeric(feature_importance['importance'])\n",
    "feature_importance.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of reg coefficients(in terms of odd ratios)\n",
    "\n",
    "Keeping everything else constant, The odds of men getting dementia as compared to women is exp(0.716563)=2.04\n",
    "times more.\n",
    "\n",
    "All else being constant, if a person gets older by a year, the probability that the person will get dementia \n",
    "increases by 1/(1+exp(-(-0.452391+0.62704977))= 54.36%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test, Y_predicted)\n",
    "df_cm = pd.DataFrame(cnf_matrix,columns={'Non-demented','Demented'},index={'Non-demented','Demented'})\n",
    "sb.heatmap(df_cm,annot=True,cbar=False)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFModel = RandomForestClassifier(n_estimators=15, max_features=6,max_depth=10,random_state=0).fit(X_train,Y_train)\n",
    "Y_predicted = RFModel.predict(X_test)\n",
    "acc = accuracy_score(Y_test,Y_predicted)\n",
    "recall = recall_score(Y_test,Y_predicted,pos_label=1)\n",
    "fpr,tpr, thresholds = roc_curve(Y_test,Y_predicted,pos_label=1)\n",
    "AUC=auc(fpr,tpr)\n",
    "compare.append(['Random Forest',acc,recall,AUC,fpr,tpr,thresholds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([RFModel.feature_importances_]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array([columns]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance=pd.DataFrame(np.hstack((np.array([columns]).T, np.array([RFModel.feature_importances_]).T)), \n",
    "                                columns=['feature', 'importance'])\n",
    "feature_importance['importance']=pd.to_numeric(feature_importance['importance'])\n",
    "feature_importance.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test, Y_predicted)\n",
    "df_cm = pd.DataFrame(cnf_matrix,columns={'Non-demented','Demented'},index={'Non-demented','Demented'})\n",
    "sb.heatmap(df_cm,annot=True,cbar=False)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare = pd.DataFrame(data=compare,columns=['Model', 'Accuracy', 'Recall', 'AUC', 'FPR', 'TPR', 'TH']);compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use DMatrix for xgbosot\n",
    "dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=Y_test)\n",
    "\n",
    "# use svmlight file for xgboost\n",
    "dump_svmlight_file(X_train, Y_train, 'dtrain.svm', zero_based=True)\n",
    "dump_svmlight_file(X_test, Y_test, 'dtest.svm', zero_based=True)\n",
    "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
    "dtest_svm = xgb.DMatrix('dtest.svm')\n",
    "\n",
    "# set xgboost params\n",
    "param = {\n",
    "    'n_estimators':1100,\n",
    "     'max_depth': 5,  # the maximum depth of each tree\n",
    "    'eta': 0.05,  # the training step for each iteration\n",
    "    'silent': 1, # logging mode - quiet\n",
    "    'objective': 'binary:logistic' # error evaluation for multiclass training\n",
    "#     'min_child_weight':1,\n",
    "#     'gamma':0.4,\n",
    "#     'subsample':0.9,\n",
    "#  'colsample_bytree':0.8\n",
    "    }  \n",
    "num_round = 15000  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing - svm file\n",
    "bst_svm = xgb.train(param, dtrain_svm, num_round)\n",
    "preds = bst_svm.predict(dtest_svm)\n",
    "\n",
    "# extracting most confident predictions\n",
    "best_preds_svm = [round(line) for line in preds]\n",
    "print(\"Accuracy\",accuracy_score(best_preds_svm,Y_test))\n",
    "print(\"Recall\",recall_score(best_preds_svm,Y_test))\n",
    "print(\"Precision\",precision_score(best_preds_svm,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = confusion_matrix(Y_test, best_preds_svm)\n",
    "df_cm = pd.DataFrame(cf,columns=['Non-demented','Demented'],index=['Non-demented','Demented'])\n",
    "sb.heatmap(df_cm,annot=True,cbar=False)\n",
    "tn = cf[0][0]\n",
    "fp = cf[0][1]\n",
    "fn = cf[1][0]\n",
    "tp = cf[1][1]\n",
    "sensitivity= tp/(tp+fn)\n",
    "specificity = tn/(tn+fp);specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a scatterplot to distinguish which points are classified correctly and which are not.\n",
    "#The x marks represents which data points are misrepresented\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler().fit(x_pca) \n",
    "\n",
    "xright,yright = X_test[Y_test==best_preds_svm],Y_test[Y_test==best_preds_svm]\n",
    "xwrong,ywrong = X_test[Y_test!=best_preds_svm],Y_test[Y_test!=best_preds_svm]\n",
    "\n",
    "X_r = scaler.transform(xright)\n",
    "X_w = scaler.transform(xwrong)\n",
    "yoyo_new_right = covar_matrix.transform(X_r)\n",
    "yoyo_new_wrong = covar_matrix.transform(X_w)\n",
    "\n",
    "sb.scatterplot(x=yoyo_new_right[:,0],y=yoyo_new_right[:,1],hue = yright)\n",
    "sb.scatterplot(x=yoyo_new_wrong[:,0],y=yoyo_new_wrong[:,1],hue = ywrong,marker = \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other method\n",
    "# ##fit model no training data\n",
    "# model = XGBClassifier(learning_rate =0.05,\n",
    "#  n_estimators=5000,\n",
    "#  max_depth=5,\n",
    "#  min_child_weight=1,\n",
    "#  gamma=0,\n",
    "#  subsample=0.8,\n",
    "#  colsample_bytree=0.8,\n",
    "#  objective= 'binary:logistic',\n",
    "#  nthread=15,\n",
    "#  scale_pos_weight=1,\n",
    "#  seed=27)\n",
    "# model.fit(X_train, Y_train)\n",
    "# # make predictions for test data\n",
    "# y_pred = model.predict(X_test)\n",
    "# predictions = [round(value) for value in y_pred]\n",
    "# # evaluate predictions\n",
    "# accuracy = accuracy_score(Y_test, predictions)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,13,2),\n",
    " 'min_child_weight':range(1,10,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.08, n_estimators=5000, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=15, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='accuracy',n_jobs=4,iid=False, cv=2)\n",
    "gsearch1.fit(X_train,Y_train)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.08, n_estimators=5000, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=15, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test2, scoring='accuracy',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X_train,Y_train)\n",
    "gsearch2.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.08, n_estimators=5000, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=15, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test3, scoring='accuracy',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(X_train,Y_train)\n",
    "gsearch3.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'n_estimators':[i for i in range(100,10000,500)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.08, n_estimators=5000, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=15, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test4, scoring='accuracy',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(X_train,Y_train)\n",
    "gsearch4.best_params_, gsearch1.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
